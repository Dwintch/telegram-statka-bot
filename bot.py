import asyncio
import os
import re
from collections import defaultdict, Counter, deque
from datetime import datetime, timedelta

from aiogram import Bot, Dispatcher, F
from aiogram.types import Message
from aiogram.enums.parse_mode import ParseMode
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.client.default import DefaultBotProperties
from apscheduler.schedulers.asyncio import AsyncIOScheduler

import openai
from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
GROUP_CHAT_ID = int(os.getenv("GROUP_CHAT_ID"))
TOPIC_ID = int(os.getenv("TOPIC_ID"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY

bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher(storage=MemoryStorage())
scheduler = AsyncIOScheduler()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
SHOP_NAMES = ["—Ö–∞–π–ø", "—è–Ω—Ç–∞—Ä—å", "–ø–æ–ª–∫–∞"]
KEYWORDS = ["–º–∞–ª–æ", "–Ω–µ—Ç—É", "–Ω–µ—Ç", "–∑–∞–∫–æ–Ω—á–∏–ª—Å—è", "–∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å", "–Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å"]

STATE_COLORS = {
    "–º–∞–ª–æ": "‚ö†Ô∏è",   # –∂–µ–ª—Ç—ã–π
    "–Ω–µ—Ç—É": "‚ùå",   # –∫—Ä–∞—Å–Ω—ã–π
    "–Ω–µ—Ç": "‚ùå",
    "–∑–∞–∫–æ–Ω—á–∏–ª—Å—è": "‚ùå",
    "–∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å": "‚ùå",
    "–Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å": "‚ùå"
}

SYNONYMS = {
    "–Ω–µ—Ç": "–Ω–µ—Ç—É",
    "–Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å": "–Ω–µ—Ç—É",
    "–∑–∞–∫–æ–Ω—á–∏–ª—Å—è": "–Ω–µ—Ç—É",
    "–∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å": "–Ω–µ—Ç—É"
}

def normalize_state(state):
    return SYNONYMS.get(state, state)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: { –º–∞–≥–∞–∑–∏–Ω: Counter((—Ç–æ–≤–∞—Ä, —Å–æ—Å—Ç–æ—è–Ω–∏–µ) : count) }
stats = defaultdict(Counter)

# –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: { user_id: deque[(message_id, text, datetime)] }
user_message_history = defaultdict(lambda: deque(maxlen=10))

def extract_data(text: str):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞–≥–∞–∑–∏–Ω, —Ç–æ–≤–∞—Ä—ã –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–º–∞–ª–æ/–Ω–µ—Ç—É) –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (shop, [(state, item), ...]) –∏–ª–∏ None.
    """
    text_lower = text.lower()
    found_shop = None
    for shop in SHOP_NAMES:
        if shop in text_lower:
            found_shop = shop
            break
    if not found_shop:
        return None

    results = []
    # –∏—â–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ "–º–∞–ª–æ —Ç–æ–≤–∞—Ä" –∏–ª–∏ "—Ç–æ–≤–∞—Ä –º–∞–ª–æ"
    for keyword in KEYWORDS:
        norm_state = normalize_state(keyword)
        # pattern "keyword item"
        pattern1 = rf"{keyword}\s+([\w\s\-\d\+]+)"
        matches1 = re.findall(pattern1, text_lower)
        for item in matches1:
            item = item.strip()
            if item:
                results.append((norm_state, item))

        # pattern "item keyword"
        pattern2 = rf"([\w\s\-\d\+]+)\s+{keyword}"
        matches2 = re.findall(pattern2, text_lower)
        for item in matches2:
            item = item.strip()
            if item:
                results.append((norm_state, item))

    if not results:
        return None

    return found_shop, results

async def analyze_messages_with_openai(texts: list[str]) -> dict:
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Ç–æ–≤–∞—Ä—ã –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∏–¥–∞:
    {
        "shop": "—Ö–∞–π–ø",
        "items": [
            {"state": "–º–∞–ª–æ", "name": "–ª–∞–±—É–±—É —ç–Ω–µ—Ä–¥–∂–∏"},
            {"state": "–Ω–µ—Ç—É", "name": "—Å—Ç–∏—á–µ–π"},
            ...
        ]
    }
    –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None.
    """
    prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞–ª–∏—á–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö.\n"
        "–ú–∞–≥–∞–∑–∏–Ω—ã: —Ö–∞–π–ø, —è–Ω—Ç–∞—Ä—å, –ø–æ–ª–∫–∞.\n"
        "–¢–æ–≤–∞—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ '–º–∞–ª–æ' –∏–ª–∏ '–Ω–µ—Ç—É'.\n"
        "–í–æ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è:\n"
        + "\n".join(f"- {t}" for t in texts) +
        "\n\n–í—ã–≤–µ–¥–∏ JSON —Å –º–∞–≥–∞–∑–∏–Ω–æ–º –∏ —Å–ø–∏—Å–∫–æ–º —Ç–æ–≤–∞—Ä–æ–≤ —Å —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏. "
        "–ü—Ä–∏–º–µ—Ä:\n"
        '{ "shop": "—Ö–∞–π–ø", "items": [ {"state": "–º–∞–ª–æ", "name": "–ª–∞–±—É–±—É —ç–Ω–µ—Ä–¥–∂–∏"}, {"state": "–Ω–µ—Ç—É", "name": "—Å—Ç–∏—á–µ–π"} ] }'
    )

    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        content = response.choices[0].message.content.strip()
        import json
        parsed = json.loads(content)
        # –±–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        if "shop" in parsed and "items" in parsed:
            return parsed
        return None
    except Exception as e:
        print(f"OpenAI parsing error: {e}")
        return None

async def update_stats_from_user_messages(user_id: int):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
    """
    messages = [msg for _, msg, dt in user_message_history[user_id] if (datetime.now() - dt).total_seconds() < 86400]
    if not messages:
        return

    parsed = await analyze_messages_with_openai(messages)
    if not parsed:
        return

    shop = parsed["shop"].lower()
    if shop not in SHOP_NAMES:
        return

    for item in parsed["items"]:
        state = normalize_state(item.get("state", ""))
        name = item.get("name", "").strip()
        if state and name:
            stats[shop][(name, state)] += 1

@dp.message(F.is_topic_message & (F.chat.id == GROUP_CHAT_ID) & (F.message_thread_id == TOPIC_ID))
async def handle_topic_message(message: Message):
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    user_id = message.from_user.id
    user_message_history[user_id].append((message.message_id, message.text or "", datetime.now()))

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞–∑–æ–≤–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–±–æ—Ä–∞
    parsed = extract_data(message.text or "")
    if parsed:
        shop, items = parsed
        for state, name in items:
            stats[shop][(name, state)] += 1
        print(f"[{shop.upper()}] {items}")

    # –¢–∞–∫–∂–µ –∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –ò–ò (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
    asyncio.create_task(update_stats_from_user_messages(user_id))

@dp.message(F.text.startswith("/—Å—Ç–∞—Ç–∫–∞"))
async def send_statka(message: Message):
    text = await format_stat()
    await message.reply(text)

def format_item(name, state, count):
    icon = STATE_COLORS.get(state, "")
    return f"{icon} <b>{name}</b> ‚Äî {state} ({count})"

async def format_stat():
    if not stats:
        return "–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö."

    lines = [f"üìä <b>–ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∫–∞</b> –Ω–∞ {datetime.now().strftime('%d.%m %H:%M')}\n"]
    for shop, items in stats.items():
        lines.append(f"<u>{shop.capitalize()}</u>:")
        for (name, state), count in items.most_common():
            lines.append(format_item(name, state, count))
        lines.append("")
    return "\n".join(lines)

async def send_daily_stat():
    text = await format_stat()
    await bot.send_message(chat_id=GROUP_CHAT_ID, message_thread_id=TOPIC_ID, text=text)

def setup_scheduler():
    scheduler.add_job(send_daily_stat, "cron", hour=0, minute=0)
    scheduler.start()

async def main():
    setup_scheduler()
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
